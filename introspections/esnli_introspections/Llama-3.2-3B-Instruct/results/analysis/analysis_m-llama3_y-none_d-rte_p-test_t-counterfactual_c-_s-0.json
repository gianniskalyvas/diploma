{"args": {"endpoint": "http://localhost:3000", "client": "VLLM", "model_name": "llama3", "model_type": "Llama3", "model_id": "meta-llama/Llama-3.1-8B-Instruct", "system_message": "none", "dataset": "RTE", "split": "test", "task": "counterfactual", "task_config": [""], "seed": 0, "max_workers": 1, "debug": false, "clean_cache": false, "dry": false}, "results": {"answer": [{"count": 241, "label": "yes", "predict": "no", "explain_predict": "yes"}, {"count": 3135, "label": "no", "predict": "no", "explain_predict": "no"}, {"count": 2833, "label": "yes", "predict": "no", "explain_predict": "no"}, {"count": 207, "label": "yes", "predict": "yes", "explain_predict": "no"}, {"count": 94, "label": "no", "predict": "no", "explain_predict": "yes"}, {"count": 81, "label": "yes", "predict": "yes", "explain_predict": "yes"}, {"count": 4, "label": "no", "predict": "yes", "explain_predict": "no"}], "faithful": 546, "correct": 3517, "faithful_and_correct": 301, "missmatch": 3, "error": 0, "total": 6598}, "durations": {"setup": 0.09291491936892271, "eval": 1698.3574456814677}}